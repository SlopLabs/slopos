//! Task-related types and constants shared between kernel subsystems.
//!
//! This module contains the canonical definitions for task management,
//! eliminating duplicate definitions across sched, drivers, boot, and mm crates.

use core::ffi::c_void;
use core::ptr;
use core::sync::atomic::{AtomicPtr, AtomicU8, AtomicU32, Ordering};

// =============================================================================
// Task Configuration Constants
// =============================================================================

pub const MAX_TASKS: usize = 32;
pub const TASK_STACK_SIZE: u64 = 0x8000; // 32KB
pub const TASK_KERNEL_STACK_SIZE: u64 = 0x8000; // 32KB
pub const TASK_NAME_MAX_LEN: usize = 32;
pub const INVALID_TASK_ID: u32 = 0xFFFF_FFFF;
pub const INVALID_PROCESS_ID: u32 = 0xFFFF_FFFF;

// =============================================================================
// Task State Constants (deprecated - use TaskStatus enum instead)
// =============================================================================

pub const TASK_STATE_INVALID: u8 = 0;
pub const TASK_STATE_READY: u8 = 1;
pub const TASK_STATE_RUNNING: u8 = 2;
pub const TASK_STATE_BLOCKED: u8 = 3;
pub const TASK_STATE_TERMINATED: u8 = 4;

// =============================================================================
// TaskStatus - Type-safe task state enum
// =============================================================================

/// Type-safe task status with explicit state machine semantics.
/// Uses `#[repr(u8)]` to maintain binary compatibility with legacy u8 state.
#[repr(u8)]
#[derive(Clone, Copy, Debug, PartialEq, Eq, Default)]
pub enum TaskStatus {
    /// Task slot is not in use
    #[default]
    Invalid = 0,
    /// Task is ready to run, waiting in a run queue
    Ready = 1,
    /// Task is currently executing on a CPU
    Running = 2,
    /// Task is blocked waiting for some event
    Blocked = 3,
    /// Task has terminated and is awaiting cleanup
    Terminated = 4,
}

impl TaskStatus {
    /// Convert from legacy u8 state constant.
    #[inline]
    pub const fn from_u8(value: u8) -> Self {
        match value {
            0 => Self::Invalid,
            1 => Self::Ready,
            2 => Self::Running,
            3 => Self::Blocked,
            4 => Self::Terminated,
            _ => Self::Invalid,
        }
    }

    /// Convert to legacy u8 state constant.
    #[inline]
    pub const fn as_u8(self) -> u8 {
        self as u8
    }

    /// Check if this state can transition to the target state.
    #[inline]
    pub const fn can_transition_to(self, target: Self) -> bool {
        match self {
            Self::Invalid => matches!(target, Self::Ready),
            Self::Ready => matches!(target, Self::Running | Self::Terminated),
            Self::Running => matches!(target, Self::Ready | Self::Blocked | Self::Terminated),
            Self::Blocked => matches!(target, Self::Ready | Self::Terminated),
            Self::Terminated => matches!(target, Self::Invalid | Self::Terminated),
        }
    }

    /// Returns true if task is in a runnable state (Ready or Running).
    #[inline]
    pub const fn is_runnable(self) -> bool {
        matches!(self, Self::Ready | Self::Running)
    }

    /// Returns true if task can be scheduled.
    #[inline]
    pub const fn is_schedulable(self) -> bool {
        matches!(self, Self::Ready)
    }
}

// =============================================================================
// BlockReason - Why a task is blocked
// =============================================================================

/// Reason why a task is in the Blocked state.
/// Helps with debugging and enables targeted wakeups.
#[repr(u8)]
#[derive(Clone, Copy, Debug, PartialEq, Eq, Default)]
pub enum BlockReason {
    #[default]
    None = 0,
    /// Waiting for another task to terminate (task ID stored separately)
    WaitingOnTask = 1,
    /// Sleeping for a specified duration
    Sleep = 2,
    /// Waiting for I/O completion
    IoWait = 3,
    /// Waiting for a mutex/lock
    MutexWait = 4,
    /// Waiting for keyboard input
    KeyboardWait = 5,
    /// Waiting for IPC message
    IpcWait = 6,
    /// Generic blocked state (legacy compatibility)
    Generic = 7,
}

impl BlockReason {
    #[inline]
    pub const fn from_u8(value: u8) -> Self {
        match value {
            0 => Self::None,
            1 => Self::WaitingOnTask,
            2 => Self::Sleep,
            3 => Self::IoWait,
            4 => Self::MutexWait,
            5 => Self::KeyboardWait,
            6 => Self::IpcWait,
            7 => Self::Generic,
            _ => Self::None,
        }
    }

    #[inline]
    pub const fn as_u8(self) -> u8 {
        self as u8
    }
}

// =============================================================================
// Task Priority Constants
// =============================================================================

pub const TASK_PRIORITY_HIGH: u8 = 0;
pub const TASK_PRIORITY_NORMAL: u8 = 1;
pub const TASK_PRIORITY_LOW: u8 = 2;
pub const TASK_PRIORITY_IDLE: u8 = 3;

// =============================================================================
// Task Flag Constants
// =============================================================================

pub const TASK_FLAG_USER_MODE: u16 = 0x01;
pub const TASK_FLAG_FPU_INITIALIZED: u16 = 0x40;
pub const TASK_FLAG_KERNEL_MODE: u16 = 0x02;
pub const TASK_FLAG_NO_PREEMPT: u16 = 0x04;
pub const TASK_FLAG_SYSTEM: u16 = 0x08;
pub const TASK_FLAG_COMPOSITOR: u16 = 0x10;
pub const TASK_FLAG_DISPLAY_EXCLUSIVE: u16 = 0x20;

// =============================================================================
// TaskContext - CPU register state for context switching
// =============================================================================

/// CPU register state saved during context switches.
/// Size: 200 bytes (0xC8) - 25 x 8-byte registers
#[repr(C, packed)]
#[derive(Clone, Copy, Default)]
pub struct TaskContext {
    pub rax: u64,
    pub rbx: u64,
    pub rcx: u64,
    pub rdx: u64,
    pub rsi: u64,
    pub rdi: u64,
    pub rbp: u64,
    pub rsp: u64,
    pub r8: u64,
    pub r9: u64,
    pub r10: u64,
    pub r11: u64,
    pub r12: u64,
    pub r13: u64,
    pub r14: u64,
    pub r15: u64,
    pub rip: u64,
    pub rflags: u64,
    pub cs: u64,
    pub ds: u64,
    pub es: u64,
    pub fs: u64,
    pub gs: u64,
    pub ss: u64,
    pub cr3: u64,
}

impl TaskContext {
    pub const fn zero() -> Self {
        Self {
            rax: 0,
            rbx: 0,
            rcx: 0,
            rdx: 0,
            rsi: 0,
            rdi: 0,
            rbp: 0,
            rsp: 0,
            r8: 0,
            r9: 0,
            r10: 0,
            r11: 0,
            r12: 0,
            r13: 0,
            r14: 0,
            r15: 0,
            rip: 0,
            rflags: 0,
            cs: 0,
            ds: 0,
            es: 0,
            fs: 0,
            gs: 0,
            ss: 0,
            cr3: 0,
        }
    }
}

use core::mem::offset_of;

#[repr(C)]
#[derive(Clone, Copy, Debug, Default)]
pub struct SwitchContext {
    pub rbx: u64,
    pub r12: u64,
    pub r13: u64,
    pub r14: u64,
    pub r15: u64,
    pub rbp: u64,
    pub rsp: u64,
    pub rflags: u64,
    pub rip: u64,
}

impl SwitchContext {
    pub const fn zero() -> Self {
        Self {
            rbx: 0,
            r12: 0,
            r13: 0,
            r14: 0,
            r15: 0,
            rbp: 0,
            rsp: 0,
            rflags: 0x202,
            rip: 0,
        }
    }

    pub const fn builder() -> SwitchContextBuilder {
        SwitchContextBuilder::new()
    }
}

#[must_use]
pub struct SwitchContextBuilder {
    ctx: SwitchContext,
    stack_configured: bool,
}

impl SwitchContextBuilder {
    pub const fn new() -> Self {
        Self {
            ctx: SwitchContext {
                rbx: 0,
                r12: 0,
                r13: 0,
                r14: 0,
                r15: 0,
                rbp: 0,
                rsp: 0,
                rflags: 0x202,
                rip: 0,
            },
            stack_configured: false,
        }
    }

    pub const fn with_entry(mut self, entry_point: u64, arg: u64) -> Self {
        self.ctx.r12 = entry_point;
        self.ctx.r13 = arg;
        self
    }

    pub const fn with_stack(mut self, stack_top: u64, trampoline: u64) -> Self {
        self.ctx.rsp = stack_top - 8;
        self.ctx.rip = trampoline;
        self.stack_configured = true;
        self
    }

    pub fn build(self) -> SwitchContext {
        assert!(self.stack_configured, "SwitchContext stack not configured");
        self.ctx
    }

    pub const fn build_unconfigured(self) -> SwitchContext {
        self.ctx
    }
}

pub const SWITCH_CTX_OFF_RBX: usize = offset_of!(SwitchContext, rbx);
pub const SWITCH_CTX_OFF_R12: usize = offset_of!(SwitchContext, r12);
pub const SWITCH_CTX_OFF_R13: usize = offset_of!(SwitchContext, r13);
pub const SWITCH_CTX_OFF_R14: usize = offset_of!(SwitchContext, r14);
pub const SWITCH_CTX_OFF_R15: usize = offset_of!(SwitchContext, r15);
pub const SWITCH_CTX_OFF_RBP: usize = offset_of!(SwitchContext, rbp);
pub const SWITCH_CTX_OFF_RSP: usize = offset_of!(SwitchContext, rsp);
pub const SWITCH_CTX_OFF_RFLAGS: usize = offset_of!(SwitchContext, rflags);
pub const SWITCH_CTX_OFF_RIP: usize = offset_of!(SwitchContext, rip);

const _: () = assert!(core::mem::size_of::<SwitchContext>() == 72);

const _: () = {
    assert!(offset_of!(SwitchContext, rbx) == 0);
    assert!(offset_of!(SwitchContext, r12) == 8);
    assert!(offset_of!(SwitchContext, r13) == 16);
    assert!(offset_of!(SwitchContext, r14) == 24);
    assert!(offset_of!(SwitchContext, r15) == 32);
    assert!(offset_of!(SwitchContext, rbp) == 40);
    assert!(offset_of!(SwitchContext, rsp) == 48);
    assert!(offset_of!(SwitchContext, rflags) == 56);
    assert!(offset_of!(SwitchContext, rip) == 64);
};

// =============================================================================
// FpuState - FPU/SSE register state for context switching
// =============================================================================

pub const FPU_STATE_SIZE: usize = 512;
pub const MXCSR_DEFAULT: u32 = 0x1F80;

// FXSAVE area offsets (Intel SDM Vol. 1, Table 10-2)
const FXSAVE_FCW_OFFSET: usize = 0;
const FXSAVE_MXCSR_OFFSET: usize = 24;

/// FXSAVE area for x87/MMX/SSE state. Must be 16-byte aligned.
#[repr(C, align(16))]
#[derive(Clone, Copy)]
pub struct FpuState {
    pub data: [u8; FPU_STATE_SIZE],
}

impl FpuState {
    pub const fn zero() -> Self {
        Self {
            data: [0u8; FPU_STATE_SIZE],
        }
    }

    /// Initialize with default FCW (0x037F) and MXCSR (0x1F80) - all exceptions masked.
    pub const fn new() -> Self {
        let mut state = Self::zero();
        // FCW: exceptions masked, 64-bit precision, round-to-nearest
        state.data[FXSAVE_FCW_OFFSET] = 0x7F;
        state.data[FXSAVE_FCW_OFFSET + 1] = 0x03;
        // MXCSR: SSE exceptions masked, round-to-nearest
        state.data[FXSAVE_MXCSR_OFFSET] = 0x80;
        state.data[FXSAVE_MXCSR_OFFSET + 1] = 0x1F;
        state
    }

    #[inline]
    pub fn as_ptr(&self) -> *const u8 {
        self.data.as_ptr()
    }

    #[inline]
    pub fn as_mut_ptr(&mut self) -> *mut u8 {
        self.data.as_mut_ptr()
    }
}

impl Default for FpuState {
    fn default() -> Self {
        Self::new()
    }
}

// =============================================================================
// Task Exit/Fault Reason Enums
// =============================================================================

/// Reason for task termination.
#[repr(u16)]
#[derive(Clone, Copy, PartialEq, Eq, Default)]
pub enum TaskExitReason {
    #[default]
    None = 0,
    Normal = 1,
    UserFault = 2,
    Kernel = 3,
}

/// Specific fault that caused task termination.
#[repr(u16)]
#[derive(Clone, Copy, PartialEq, Eq, Default)]
pub enum TaskFaultReason {
    #[default]
    None = 0,
    UserPage = 1,
    UserGp = 2,
    UserUd = 3,
    UserDeviceNa = 4,
}

// =============================================================================
// Task Struct Layout Constants (for assembly access)
// =============================================================================

// Offset from &Task.context to &Task.fpu_state
// TaskContext is 200 bytes (packed), FpuState needs 16-byte alignment
// So there's 8 bytes padding: 200 + 8 = 208 (0xD0)
pub const TASK_FPU_OFFSET_FROM_CONTEXT: usize = 0xD0;

// =============================================================================
// Task Struct
// =============================================================================

#[repr(C)]
pub struct Task {
    pub task_id: u32,
    pub name: [u8; TASK_NAME_MAX_LEN],
    state_atomic: AtomicU8,
    pub priority: u8,
    pub flags: u16,
    pub block_reason: BlockReason,
    _pad0: [u8; 3],
    pub process_id: u32,
    pub stack_base: u64,
    pub stack_size: u64,
    pub stack_pointer: u64,
    pub kernel_stack_base: u64,
    pub kernel_stack_top: u64,
    pub kernel_stack_size: u64,
    pub entry_point: u64,
    pub entry_arg: *mut c_void,
    pub context: TaskContext,
    pub fpu_state: FpuState,
    pub time_slice: u64,
    pub time_slice_remaining: u64,
    pub total_runtime: u64,
    pub creation_time: u64,
    pub yield_count: u32,
    pub last_run_timestamp: u64,
    pub waiting_on: AtomicU32,
    pub user_started: u8,
    pub context_from_user: u8,
    pub exit_reason: TaskExitReason,
    pub fault_reason: TaskFaultReason,
    pub exit_code: u32,
    pub fate_token: u32,
    pub fate_value: u32,
    pub fate_pending: u8,
    pub cpu_affinity: u32,
    pub last_cpu: u8,
    pub migration_count: u32,
    pub switch_ctx: SwitchContext,
    pub next_ready: *mut Task,
    /// Linkage for remote wake inbox (separate from ready queue linkage)
    pub next_inbox: AtomicPtr<Task>,
    /// Reference count for safe deferred reclamation
    pub refcnt: AtomicU32,
}

impl Task {
    pub const fn invalid() -> Self {
        Self {
            task_id: INVALID_TASK_ID,
            name: [0; TASK_NAME_MAX_LEN],
            state_atomic: AtomicU8::new(TASK_STATE_INVALID),
            priority: TASK_PRIORITY_NORMAL,
            flags: 0,
            block_reason: BlockReason::None,
            _pad0: [0; 3],
            process_id: INVALID_PROCESS_ID,
            stack_base: 0,
            stack_size: 0,
            stack_pointer: 0,
            kernel_stack_base: 0,
            kernel_stack_top: 0,
            kernel_stack_size: 0,
            entry_point: 0,
            entry_arg: ptr::null_mut(),
            context: TaskContext::zero(),
            fpu_state: FpuState::new(),
            time_slice: 0,
            time_slice_remaining: 0,
            total_runtime: 0,
            creation_time: 0,
            yield_count: 0,
            last_run_timestamp: 0,
            waiting_on: AtomicU32::new(INVALID_TASK_ID),
            user_started: 0,
            context_from_user: 0,
            exit_reason: TaskExitReason::None,
            fault_reason: TaskFaultReason::None,
            exit_code: 0,
            fate_token: 0,
            fate_value: 0,
            fate_pending: 0,
            cpu_affinity: 0,
            last_cpu: 0,
            migration_count: 0,
            switch_ctx: SwitchContext::zero(),
            next_ready: ptr::null_mut(),
            next_inbox: AtomicPtr::new(ptr::null_mut()),
            refcnt: AtomicU32::new(0),
        }
    }

    #[inline]
    pub fn state(&self) -> u8 {
        self.state_atomic.load(Ordering::Acquire)
    }

    #[inline]
    pub fn set_state(&self, state: u8) {
        self.state_atomic.store(state, Ordering::Release);
    }

    #[inline]
    pub fn status(&self) -> TaskStatus {
        TaskStatus::from_u8(self.state())
    }

    #[inline]
    pub fn set_status(&self, status: TaskStatus) {
        self.set_state(status.as_u8());
    }

    #[inline]
    pub fn try_transition_to(&self, target: TaskStatus) -> bool {
        let current = self.state();
        let current_status = TaskStatus::from_u8(current);
        if current_status.can_transition_to(target) {
            match self.state_atomic.compare_exchange(
                current,
                target.as_u8(),
                Ordering::AcqRel,
                Ordering::Acquire,
            ) {
                Ok(_) => true,
                Err(_) => false,
            }
        } else {
            false
        }
    }

    #[inline]
    pub fn mark_ready(&self) -> bool {
        self.try_transition_to(TaskStatus::Ready)
    }

    #[inline]
    pub fn mark_ready_and_clear_block(&mut self) -> bool {
        if self.try_transition_to(TaskStatus::Ready) {
            self.block_reason = BlockReason::None;
            true
        } else {
            false
        }
    }

    #[inline]
    pub fn mark_running(&self) -> bool {
        self.try_transition_to(TaskStatus::Running)
    }

    #[inline]
    pub fn block(&mut self, reason: BlockReason) -> bool {
        if self.try_transition_to(TaskStatus::Blocked) {
            self.block_reason = reason;
            true
        } else {
            false
        }
    }

    #[inline]
    pub fn block_atomic(&self) -> bool {
        self.try_transition_to(TaskStatus::Blocked)
    }

    #[inline]
    pub fn terminate(&self) -> bool {
        self.try_transition_to(TaskStatus::Terminated)
    }

    #[inline]
    pub fn is_blocked(&self) -> bool {
        self.status() == TaskStatus::Blocked
    }

    #[inline]
    pub fn is_ready(&self) -> bool {
        self.status() == TaskStatus::Ready
    }

    #[inline]
    pub fn is_running(&self) -> bool {
        self.status() == TaskStatus::Running
    }

    #[inline]
    pub fn is_terminated(&self) -> bool {
        self.status() == TaskStatus::Terminated
    }

    pub fn clone_from(&mut self, other: &Task) {
        self.task_id = other.task_id;
        self.name = other.name;
        self.set_state(other.state());
        self.priority = other.priority;
        self.flags = other.flags;
        self.block_reason = other.block_reason;
        self._pad0 = other._pad0;
        self.process_id = other.process_id;
        self.stack_base = other.stack_base;
        self.stack_size = other.stack_size;
        self.stack_pointer = other.stack_pointer;
        self.kernel_stack_base = other.kernel_stack_base;
        self.kernel_stack_top = other.kernel_stack_top;
        self.kernel_stack_size = other.kernel_stack_size;
        self.entry_point = other.entry_point;
        self.entry_arg = other.entry_arg;
        self.context = other.context;
        self.fpu_state = other.fpu_state;
        self.time_slice = other.time_slice;
        self.time_slice_remaining = other.time_slice_remaining;
        self.total_runtime = other.total_runtime;
        self.creation_time = other.creation_time;
        self.yield_count = other.yield_count;
        self.last_run_timestamp = other.last_run_timestamp;
        self.waiting_on
            .store(other.waiting_on.load(Ordering::Acquire), Ordering::Release);
        self.user_started = other.user_started;
        self.context_from_user = other.context_from_user;
        self.exit_reason = other.exit_reason;
        self.fault_reason = other.fault_reason;
        self.exit_code = other.exit_code;
        self.fate_token = other.fate_token;
        self.fate_value = other.fate_value;
        self.fate_pending = other.fate_pending;
        self.cpu_affinity = other.cpu_affinity;
        self.last_cpu = other.last_cpu;
        self.migration_count = other.migration_count;
        self.switch_ctx = other.switch_ctx;
        self.next_ready = other.next_ready;
        self.next_inbox
            .store(other.next_inbox.load(Ordering::Acquire), Ordering::Release);
        self.refcnt.store(0, Ordering::Release); // Don't clone refcount - start fresh
    }

    /// Increment reference count. Returns new count.
    #[inline]
    pub fn inc_ref(&self) -> u32 {
        self.refcnt.fetch_add(1, Ordering::AcqRel) + 1
    }

    /// Decrement reference count. Returns true if this was the last reference.
    #[inline]
    pub fn dec_ref(&self) -> bool {
        self.refcnt.fetch_sub(1, Ordering::AcqRel) == 1
    }

    /// Get current reference count.
    #[inline]
    pub fn ref_count(&self) -> u32 {
        self.refcnt.load(Ordering::Acquire)
    }
}

// =============================================================================
// TaskExitRecord - for tracking task termination
// =============================================================================

/// Record of task termination for post-mortem inspection.
#[repr(C)]
#[derive(Clone, Copy)]
pub struct TaskExitRecord {
    pub task_id: u32,
    pub exit_reason: TaskExitReason,
    pub fault_reason: TaskFaultReason,
    pub exit_code: u32,
}

impl TaskExitRecord {
    /// Create an empty exit record.
    pub const fn empty() -> Self {
        Self {
            task_id: INVALID_TASK_ID,
            exit_reason: TaskExitReason::None,
            fault_reason: TaskFaultReason::None,
            exit_code: 0,
        }
    }
}

// =============================================================================
// IdtEntry - Interrupt Descriptor Table entry
// =============================================================================

/// x86-64 IDT (Interrupt Descriptor Table) entry.
/// Used for setting up interrupt and exception handlers.
#[repr(C, packed)]
#[derive(Copy, Clone)]
pub struct IdtEntry {
    pub offset_low: u16,
    pub selector: u16,
    pub ist: u8,
    pub type_attr: u8,
    pub offset_mid: u16,
    pub offset_high: u32,
    pub zero: u32,
}

impl IdtEntry {
    /// Create a zeroed IDT entry.
    pub const fn zero() -> Self {
        Self {
            offset_low: 0,
            selector: 0,
            ist: 0,
            type_attr: 0,
            offset_mid: 0,
            offset_high: 0,
            zero: 0,
        }
    }
}
